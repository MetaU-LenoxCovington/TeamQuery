{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc8a98ce-486e-4f32-81c2-1714dcdb6375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import re\n",
    "import textwrap\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    RapidOcrOptions,\n",
    "    smolvlm_picture_description,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import HTML, display\n",
    "from ollama import chat\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f329bc95-27dd-4ffa-bef4-8e511ed3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions(\n",
    "    generate_page_images=True,\n",
    "    images_scale=1.00,\n",
    "    do_ocr=True,\n",
    "    do_picture_description=True,\n",
    "    ocr_options=RapidOcrOptions(),\n",
    "    picture_description_options=smolvlm_picture_description,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "428f6304-805a-447c-afc3-2deb73e96f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('test_data/House Rules.pdf')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#document_path = Path(\"test_data/01. House Rules - Current Version.pdf\")\n",
    "document_path = Path(\"test_data/House Rules.pdf\")\n",
    "document_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "672ee4e9-9fa6-461e-b60b-17409487928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 3.27 s, total: 56.4 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = converter.convert(document_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78a81898-663e-41d8-978b-b2916c59b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ab937-f15a-4973-a6af-d7b4bae30019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b88f102a-a59c-4f01-9ea8-33f3d9d047bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_ref='#/pictures/0' parent=RefItem(cref='#/body') children=[RefItem(cref='#/texts/2')] content_layer=<ContentLayer.BODY: 'body'> label=<DocItemLabel.PICTURE: 'picture'> prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=110.65599822998047, t=489.8112487792969, r=494.0281982421875, b=200.79742431640625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))] captions=[] references=[] footnotes=[] image=None annotations=[DescriptionAnnotation(kind='description', text='In this image we can see a building with windows and balconies. We can also see a tree and a bicycle. We can also see the sky with clouds.', provenance='HuggingFaceTB/SmolVLM-256M-Instruct')]\n"
     ]
    }
   ],
   "source": [
    "#print(document.pictures[0].annotations)\n",
    "print(document.pictures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77dd3aa2-87de-4445-9119-3304296860be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures: 1\n",
      "Picture 0: loaded image: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pictures:\", len(document.pictures))\n",
    "for i, pic in enumerate(document.pictures):\n",
    "    print(f\"Picture {i}: loaded image: {pic.image is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6639ab2-c829-4466-b0aa-e0fed6d71137",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for picture in document.pictures:\n",
    "    for annotation in picture.annotations:\n",
    "            annotations.append(annotation.text)\n",
    "assert len(annotations) == len(document.pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2047e7d-9150-4f90-b823-9d656872a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_occurences(text, target, replacements):\n",
    "    for replacement in replacements:\n",
    "        if target in text:\n",
    "            text = text.replace(target, replacement, 1)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"No more occurences of '{target}' found in the text for replacement ({replacement}).\"\n",
    "            )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60c0da16-987a-4105-b694-2a4ef2e1bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PLACEHOLDER = \"<!-- image_placeholder -->\"\n",
    "PAGE_BREAK_PLACEHOLDER = \"<!-- page_break -->\"\n",
    "text = document.export_to_markdown(\n",
    "    page_break_placeholder=PAGE_BREAK_PLACEHOLDER, image_placeholder=IMAGE_PLACEHOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c0a6b-5f7f-4963-9d69-75b03424dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b62abe-0843-4c1b-950f-f19bcc383875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(replace_occurences(text, IMAGE_PLACEHOLDER, annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0d2d4dc-3645-4e6c-887e-14c649e1e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(\n",
    "    document_path: Path, converter: DocumentConverter, n_pages: int = -1\n",
    ") -> str:\n",
    "    result = converter.convert(document_path)\n",
    "    document = result.document\n",
    "\n",
    "    annotations = []\n",
    "    for picture in document.pictures:\n",
    "        print(picture)\n",
    "        for annotation in picture.annotations:\n",
    "            annotations.append(annotation.text)\n",
    "\n",
    "    if(len(annotations) == len(document.pictures)):\n",
    "        console.log(\"mismatch in number of annotations and number or pictures\")\n",
    "    text = document.export_to_markdown(\n",
    "        page_break_placeholder=PAGE_BREAK_PLACEHOLDER,\n",
    "        image_placeholder=IMAGE_PLACEHOLDER,\n",
    "    )\n",
    "    text = replace_occurences(text, IMAGE_PLACEHOLDER, annotations)\n",
    "    if n_pages == -1:\n",
    "        return text\n",
    "    return PAGE_BREAK_PLACEHOLDER.join(text.split(PAGE_BREAK_PLACEHOLDER)[:n_pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d999229f-0e27-4253-a079-980e21ce88e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_ref='#/pictures/0' parent=RefItem(cref='#/body') children=[RefItem(cref='#/texts/2')] content_layer=<ContentLayer.BODY: 'body'> label=<DocItemLabel.PICTURE: 'picture'> prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=110.65599822998047, t=489.8112487792969, r=494.0281982421875, b=200.79742431640625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))] captions=[] references=[] footnotes=[] image=None annotations=[DescriptionAnnotation(kind='description', text='In this image we can see a building with windows and balconies. We can also see a tree and a bicycle. We can also see the sky with clouds.', provenance='HuggingFaceTB/SmolVLM-256M-Instruct')]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_path = Path(\"test_data/House Rules.pdf\")\n",
    "document_text = process_document(document_path, converter, n_pages=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6031c37e-d4fa-4f43-9346-ece0b40d1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1615\n"
     ]
    }
   ],
   "source": [
    "print(len(document_text.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662f710-0197-461e-aa9c-8a2dc79ae5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e8fb60f-9299-4c19-8eaa-bcbec1b6f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_PATTERN = \"\\n\"\n",
    "chunks = document_text.split(SPLIT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "16d15e52-0dec-494b-8b92-aed509bdd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = \"\"\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if chunk.startswith(\"#\"):\n",
    "        chunk = f\"#{chunk}\"\n",
    "    chunked_text += f\"<|start_chunk_{i}>\\n{chunk}<|end_chunk_{i}|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865b143-f2de-412c-9e72-aeade888e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d41a9de-2b3e-4735-af56-4971407fbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"hf.co/google/gemma-3-12b-it-qat-q4_0-gguf:latest\"\n",
    "TEMPERATURE = 0.0\n",
    "MIN_P = 0.0\n",
    "REPEAT_PENALTY = 1.0\n",
    "TOP_K = 64\n",
    "TOP_P = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b53dfa6-ed2e-438b-aa2e-bd05d493be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(prompt: str) -> str:\n",
    "    response = chat(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        keep_alive=\"1h\",\n",
    "        options={\n",
    "            \"num_ctx\": 16384,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"min_p\": MIN_P,\n",
    "            \"repeat_penalty\": REPEAT_PENALTY,\n",
    "            \"top_k\": TOP_K,\n",
    "            \"top_p\": TOP_P,\n",
    "        },\n",
    "    )\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c6e2e1a-6602-45dd-bbaa-19a4d4a38f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKING_PROMPT = \"\"\"\n",
    "You are an assistant specialized in splitting text into semantically consistent sections.\n",
    "\n",
    "<instructions>\n",
    "    <instruction>The text has been divided into chunks, each marked with <|start_chunk_X|> and <|end_chunk_X|> tags, where X is the chunk number</instruction>\n",
    "    <instruction>Identify points where splits should occur, such that consecutive chunks of similar themese stay together</instruction>\n",
    "    <instruction>Each chunk must be between 200 and 1000 words</instruction>\n",
    "    <instruction>If chunks 1 and 2 belong together but chunk 3 starts a new topic, suggest a split after chunk 2</instruction>\n",
    "    <instruction>The chunks must be listed in ascending order</instruction>\n",
    "    <instruction>Provide your response in the form: 'split_after: 3, 5'</instruction>\n",
    "</instructions>\"\n",
    "\n",
    "This is the document text:\n",
    "<document>\n",
    "{document_text}\n",
    "</document>\n",
    "\n",
    "Respond only with the IDs of the chunks where you believe a split should occur.\n",
    "YOU MUST RESPOND WITH AT LEAST ONE SPLIT\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b9cd7-933d-4aec-8676-05599734a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CHUNKING_PROMPT.format(document_text=chunked_text)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1912b769-b392-4a91-aec5-a1a5ef2e091b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 ms, sys: 2.2 ms, total: 3.66 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresponse = call_model(prompt)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1434\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1432\u001b[39m st = clock2()\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_ctx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16384\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMIN_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrepeat_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mREPEAT_PENALTY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOP_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOP_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/ollama/_client.py:342\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    298\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    299\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    308\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    309\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    311\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/MetaU/TeamQuery/pythonService/venv/lib/python3.12/site-packages/ollama/_client.py:126\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = call_model(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c79eff-d86a-4958-bb3b-da58fb1b9a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TeamQuery Python Environment",
   "language": "python",
   "name": "teamquery-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
